{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":10272092,"sourceType":"datasetVersion","datasetId":6355668},{"sourceId":10272104,"sourceType":"datasetVersion","datasetId":6355678},{"sourceId":10297808,"sourceType":"datasetVersion","datasetId":6373855},{"sourceId":10298407,"sourceType":"datasetVersion","datasetId":6374257}],"dockerImageVersionId":30823,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:58.923919Z","iopub.execute_input":"2025-03-11T05:32:58.924228Z","iopub.status.idle":"2025-03-11T05:32:59.288671Z","shell.execute_reply.started":"2025-03-11T05:32:58.924194Z","shell.execute_reply":"2025-03-11T05:32:59.287803Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\n/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\n/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\n/kaggle/input/bert-model/bert_base_uncased_model/config.json\n/kaggle/input/bert-model/bert_base_uncased_model/model.safetensors\n/kaggle/input/bert-token/bert_base_token/tokenizer.json\n/kaggle/input/bert-token/bert_base_token/tokenizer_config.json\n/kaggle/input/bert-token/bert_base_token/special_tokens_map.json\n/kaggle/input/bert-token/bert_base_token/vocab.txt\n/kaggle/input/token-ml/tokenzer_ml_bert/tokenizer.json\n/kaggle/input/token-ml/tokenzer_ml_bert/tokenizer_config.json\n/kaggle/input/token-ml/tokenzer_ml_bert/special_tokens_map.json\n/kaggle/input/token-ml/tokenzer_ml_bert/vocab.txt\n/kaggle/input/model-ml/Model_ml_bert/config.json\n/kaggle/input/model-ml/Model_ml_bert/model.safetensors\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"ss = pd.read_csv(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\")\nss.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:59.289732Z","iopub.execute_input":"2025-03-11T05:32:59.290230Z","iopub.status.idle":"2025-03-11T05:32:59.315793Z","shell.execute_reply.started":"2025-03-11T05:32:59.290197Z","shell.execute_reply":"2025-03-11T05:32:59.314999Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        id   winner\n0   327228  model_a\n1  1139415  model_a\n2  1235630  model_a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>model_a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>model_a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>model_a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from datasets import Dataset\n\n# Load the datasets from parquet files\ntrain_df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\ntest_df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n\n# Prepare training dataset for classification\ntrain_samples = []\nfor _, row in train_df.iterrows():\n    train_samples.append({\n        'prompt': row['prompt'],\n        'response': row['response_a'],\n        'winner': 0 if row['winner'] == 'model_a' else 1\n    })\n    train_samples.append({\n        'prompt': row['prompt'],\n        'response': row['response_b'],\n        'winner': 1 if row['winner'] == 'model_b' else 0\n    })\n\n# Convert to a Hugging Face Dataset\ntrain_dataset = Dataset.from_dict({\n    'prompt': [sample['prompt'] for sample in train_samples],\n    'response': [sample['response'] for sample in train_samples],\n    'winner': [sample['winner'] for sample in train_samples],\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:59.317042Z","iopub.execute_input":"2025-03-11T05:32:59.317302Z","iopub.status.idle":"2025-03-11T05:33:11.279094Z","shell.execute_reply.started":"2025-03-11T05:32:59.317261Z","shell.execute_reply":"2025-03-11T05:33:11.278191Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.279927Z","iopub.execute_input":"2025-03-11T05:33:11.280309Z","iopub.status.idle":"2025-03-11T05:33:11.290683Z","shell.execute_reply.started":"2025-03-11T05:33:11.280278Z","shell.execute_reply":"2025-03-11T05:33:11.289818Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  id  \\\n0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n2  0003800d510e38803efba5ceaec122bc66408fe367b0be...   \n3  00072026c68f5418ef2da238394e418ce72a534b9b22d5...   \n4  0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...   \n\n                                              prompt  \\\n0                                 vie≈° po Slovensky?   \n1  You will be given a piece of news. Analyze it ...   \n2  D√∂rt basamaklƒ±, rakamlarƒ± birbirinden ve sƒ±fƒ±r...   \n3  ÌòÑÏû¨ Ï∂îÏ≤úÎêú ÌÉë 3 Ï¢ÖÎ™©Ïù∏ Cabaletta Bio (CABA), Rocket Ph...   \n4                                  Please be boring    \n\n                                          response_a  \\\n0   √Åno, hovor√≠m po slovensky. Ako v√°m m√¥≈æem pom√¥c≈•?   \n1  Let's break down the news and analyze it accor...   \n2  Bu soruyu √ß√∂zmek i√ßin, verilen ko≈üullarƒ± adƒ±m ...   \n3  Ï£ÑÏÜ°ÌïòÏßÄÎßå Ï†ÄÎäî Í∏àÏúµ Ï°∞Ïñ∏ÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§. Ï†ÄÎäî AI Î™®Îç∏Ïù¥Î©∞, Ìà¨Ïûê Í≤∞Ï†ïÏóê...   \n4  Alright, I'll be as boring as possible.\\n\\nTod...   \n\n                                          response_b   winner  \\\n0  √Åno, veƒè som tu! M√¥≈æem ti pom√¥c≈• s ot√°zkami al...  model_a   \n1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n2  Bu problemi adƒ±m adƒ±m √ß√∂zelim:\\n\\n1) ABCD - DC...  model_a   \n3  ÌòÑÏû¨ Ï∂îÏ≤úÎêú ÌÉë 3 Ï¢ÖÎ™©Ïóê ÏàúÏúÑÎ•º Îß§Í∏∞Í∏∞ ÏúÑÌï¥ÏÑúÎäî Ïó¨Îü¨ Í∞ÄÏßÄ ÏöîÏÜåÎì§ÏùÑ Í≥†Î†§Ìï¥Ïïº Ìï©Îãà...  model_b   \n4  Understood. Here is a straightforward, unadorn...  model_a   \n\n               model_a                          model_b language  \n0           o1-preview               reka-core-20240904   Slovak  \n1       gemma-2-27b-it             gemini-1.5-flash-002  Russian  \n2   gpt-4-0125-preview       claude-3-5-sonnet-20240620  Turkish  \n3        gemma-2-2b-it  llama-3.1-nemotron-70b-instruct  English  \n4  reka-flash-20240722                grok-2-2024-08-13  English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n      <td>vie≈° po Slovensky?</td>\n      <td>√Åno, hovor√≠m po slovensky. Ako v√°m m√¥≈æem pom√¥c≈•?</td>\n      <td>√Åno, veƒè som tu! M√¥≈æem ti pom√¥c≈• s ot√°zkami al...</td>\n      <td>model_a</td>\n      <td>o1-preview</td>\n      <td>reka-core-20240904</td>\n      <td>Slovak</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n      <td>You will be given a piece of news. Analyze it ...</td>\n      <td>Let's break down the news and analyze it accor...</td>\n      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n      <td>model_a</td>\n      <td>gemma-2-27b-it</td>\n      <td>gemini-1.5-flash-002</td>\n      <td>Russian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003800d510e38803efba5ceaec122bc66408fe367b0be...</td>\n      <td>D√∂rt basamaklƒ±, rakamlarƒ± birbirinden ve sƒ±fƒ±r...</td>\n      <td>Bu soruyu √ß√∂zmek i√ßin, verilen ko≈üullarƒ± adƒ±m ...</td>\n      <td>Bu problemi adƒ±m adƒ±m √ß√∂zelim:\\n\\n1) ABCD - DC...</td>\n      <td>model_a</td>\n      <td>gpt-4-0125-preview</td>\n      <td>claude-3-5-sonnet-20240620</td>\n      <td>Turkish</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00072026c68f5418ef2da238394e418ce72a534b9b22d5...</td>\n      <td>ÌòÑÏû¨ Ï∂îÏ≤úÎêú ÌÉë 3 Ï¢ÖÎ™©Ïù∏ Cabaletta Bio (CABA), Rocket Ph...</td>\n      <td>Ï£ÑÏÜ°ÌïòÏßÄÎßå Ï†ÄÎäî Í∏àÏúµ Ï°∞Ïñ∏ÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§. Ï†ÄÎäî AI Î™®Îç∏Ïù¥Î©∞, Ìà¨Ïûê Í≤∞Ï†ïÏóê...</td>\n      <td>ÌòÑÏû¨ Ï∂îÏ≤úÎêú ÌÉë 3 Ï¢ÖÎ™©Ïóê ÏàúÏúÑÎ•º Îß§Í∏∞Í∏∞ ÏúÑÌï¥ÏÑúÎäî Ïó¨Îü¨ Í∞ÄÏßÄ ÏöîÏÜåÎì§ÏùÑ Í≥†Î†§Ìï¥Ïïº Ìï©Îãà...</td>\n      <td>model_b</td>\n      <td>gemma-2-2b-it</td>\n      <td>llama-3.1-nemotron-70b-instruct</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...</td>\n      <td>Please be boring</td>\n      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n      <td>Understood. Here is a straightforward, unadorn...</td>\n      <td>model_a</td>\n      <td>reka-flash-20240722</td>\n      <td>grok-2-2024-08-13</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df[\"language\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.293361Z","iopub.execute_input":"2025-03-11T05:33:11.293587Z","iopub.status.idle":"2025-03-11T05:33:11.314682Z","shell.execute_reply.started":"2025-03-11T05:33:11.293567Z","shell.execute_reply":"2025-03-11T05:33:11.314037Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['Slovak', 'Russian', 'Turkish', 'English', 'Korean', 'Swedish',\n       'Vietnamese', 'Finnish', 'unknown', 'Chinese', 'Hungarian',\n       'Spanish', 'Polish', 'Japanese', 'Dutch', 'German', 'Yiddish',\n       'Italian', 'French', 'Indonesian', 'Persian', 'Portuguese',\n       'Catalan', 'Czech', 'Ukrainian', 'Arabic', 'Bislama', 'Bulgarian',\n       'Romanian', 'Armenian', 'Xhosa', 'Yoruba', 'Thai', 'Serbian',\n       'Slovenian', 'Tamil', 'Sanskrit', 'xx', 'Malay', 'Swahili',\n       'Irish', 'Lithuanian', 'Waray', 'Kyrgyz', 'Kalaallisut', 'Latin',\n       'Nauru', 'Corsican', 'Khasi', 'Norwegian', 'Hebrew', 'Faroese',\n       'Azerbaijani', 'Danish', 'Abkhazian', 'Oromo', 'Ganda', 'Zhuang',\n       'Estonian', 'Basque', 'Uzbek', 'Pashto', 'Afrikaans', 'Scots',\n       'Macedonian', 'Greek', 'Luxembourgish', 'Latvian', 'Wolof',\n       'Croatian', 'Esperanto', 'Galician', 'Javanese', 'Bosnian',\n       'Tongan', 'Belarusian', 'Bangla', 'Romansh', 'Sundanese',\n       'Tagalog', 'Southern Sotho', 'Mongolian', 'Dzongkha',\n       'Norwegian Nynorsk', 'Khmer', 'Amharic', 'Shona', 'Bashkir',\n       'Inuktitut', 'Afar', 'Malagasy', 'Icelandic', 'Manx',\n       'Interlingue', 'Occitan', 'Interlingua', 'Tsonga', 'Swati',\n       'Tatar', 'Tibetan', 'Hindi', 'Assamese', 'Haitian Creole',\n       'Albanian', 'Hmong', 'Kinyarwanda', 'Welsh', 'Turkmen', 'Akan',\n       'Rundi', 'zzp', 'Aymara', 'Hausa', 'Guarani', 'Nyanja',\n       'Scottish Gaelic', 'Tswana', 'Lingala', 'Kazakh', 'Breton',\n       'Klingon', 'Volap√ºk', 'Hawaiian', 'Kurdish', 'Quechua', 'Samoan',\n       'Telugu', 'Sindhi'], dtype=object)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.315933Z","iopub.execute_input":"2025-03-11T05:33:11.316178Z","iopub.status.idle":"2025-03-11T05:33:11.331648Z","shell.execute_reply.started":"2025-03-11T05:33:11.316158Z","shell.execute_reply":"2025-03-11T05:33:11.330851Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   327228  Caso Cl√≠nico: Un hombre de 70 a√±os con anteced...   \n1  1139415   Peel Company received a cash dividend from a ...   \n2  1235630  H√° um grave problema com o rel√≥gio da torre da...   \n\n                                          response_a  \\\n0  **Diagn√≥stico Diferencial de Anemia en Pacient...   \n1  The correct answer is **(a) No   No**. Here's ...   \n2  Dois problemas interessantes!\\n\\n**Problema 1:...   \n\n                                          response_b  scored  \n0  Bas√°ndonos en el caso cl√≠nico presentado, pode...   False  \n1  The correct answer is **(a) No No**. Here's wh...   False  \n2  Vamos resolver os dois problemas em sequ√™ncia....   False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>scored</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>Caso Cl√≠nico: Un hombre de 70 a√±os con anteced...</td>\n      <td>**Diagn√≥stico Diferencial de Anemia en Pacient...</td>\n      <td>Bas√°ndonos en el caso cl√≠nico presentado, pode...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>Peel Company received a cash dividend from a ...</td>\n      <td>The correct answer is **(a) No   No**. Here's ...</td>\n      <td>The correct answer is **(a) No No**. Here's wh...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>H√° um grave problema com o rel√≥gio da torre da...</td>\n      <td>Dois problemas interessantes!\\n\\n**Problema 1:...</td>\n      <td>Vamos resolver os dois problemas em sequ√™ncia....</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Use a subset of the dataset for quick testing\n#train_dataset = train_dataset.select(range(2000))  # Select first 1000 examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.332244Z","iopub.execute_input":"2025-03-11T05:33:11.332436Z","iopub.status.idle":"2025-03-11T05:33:11.341899Z","shell.execute_reply.started":"2025-03-11T05:33:11.332410Z","shell.execute_reply":"2025-03-11T05:33:11.341269Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.342580Z","iopub.execute_input":"2025-03-11T05:33:11.342774Z","iopub.status.idle":"2025-03-11T05:33:11.353856Z","shell.execute_reply.started":"2025-03-11T05:33:11.342751Z","shell.execute_reply":"2025-03-11T05:33:11.352859Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'response', 'winner'],\n    num_rows: 96878\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nimport torch.nn.utils.weight_norm\nimport torch.nn as nn\n\nclass WeightNormModel(AutoModelForSequenceClassification):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Applying weight normalization on the classifier layer\n        self.classifier = torch.nn.utils.weight_norm(self.classifier)\n\n# Load your model with weight normalization\n#model = WeightNormModel.from_pretrained(\n    #\"/kaggle/input/bert-model/bert_base_uncased_model\",\n    #num_labels=2,\n#)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"/kaggle/input/model-ml/Model_ml_bert\",  # You can choose other model variants as well\n    num_labels=2,\n    id2label={0: \"model_a\", 1: \"model_b\"},  # Labels corresponding to models\n    label2id={\"model_a\": 0, \"model_b\": 1},\n)\n\n# Freeze all parameters in the base model\nfor param in model.base_model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the last 3 layers of the transformer\nnum_layers = len(model.base_model.encoder.layer)\nfor layer in model.base_model.encoder.layer[num_layers-3:]:\n    for param in layer.parameters():\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.354713Z","iopub.execute_input":"2025-03-11T05:33:11.354995Z","iopub.status.idle":"2025-03-11T05:33:16.728657Z","shell.execute_reply.started":"2025-03-11T05:33:11.354975Z","shell.execute_reply":"2025-03-11T05:33:16.727963Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of parameters that require gradients: {total_parameters}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:16.729455Z","iopub.execute_input":"2025-03-11T05:33:16.729894Z","iopub.status.idle":"2025-03-11T05:33:16.735233Z","shell.execute_reply.started":"2025-03-11T05:33:16.729846Z","shell.execute_reply":"2025-03-11T05:33:16.734372Z"}},"outputs":[{"name":"stdout","text":"Number of parameters that require gradients: 21265154\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\nfrom transformers import AutoTokenizer\nfrom datasets import DatasetDict\nimport torch\nimport random\n\n# Set random seed for reproducibility\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n# Ensure deterministic behavior\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/token-ml/tokenzer_ml_bert\")\n\n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples['prompt'], examples['response'], return_tensors='pt', padding=True, truncation=True)\n\n# Tokenize the dataset\ntokenized_train = train_dataset.map(\n    lambda examples: {\n        **tokenize_function(examples),\n        \"labels\": examples[\"winner\"],  # Replace 'label' with the actual column name in your dataset\n    },\n    batched=True,\n)\n\n# Split the tokenized_train dataset into training and evaluation datasets\nsplit_datasets = tokenized_train.train_test_split(test_size=0.2, seed=42)  # Adjust test_size as needed\ntokenized_train = split_datasets[\"train\"]\ntokenized_eval = split_datasets[\"test\"]\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (predictions == labels).mean()}\n\n\n# Prepare training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./model_output\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=150,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\",  # Disable logging to WandB\n)\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_eval,  # Provide a validation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,  # Add compute_metrics\n)\n\n# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:16.736093Z","iopub.execute_input":"2025-03-11T05:33:16.736327Z","iopub.status.idle":"2025-03-11T08:59:31.528209Z","shell.execute_reply.started":"2025-03-11T05:33:16.736297Z","shell.execute_reply":"2025-03-11T08:59:31.527517Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/96878 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ba6b8401f874b52ae2562f8adf855cb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1295' max='1295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1295/1295 3:22:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.693700</td>\n      <td>0.693084</td>\n      <td>0.507690</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.691500</td>\n      <td>0.692130</td>\n      <td>0.513625</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.688400</td>\n      <td>0.688886</td>\n      <td>0.535456</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.657400</td>\n      <td>0.685461</td>\n      <td>0.567971</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.600900</td>\n      <td>0.705334</td>\n      <td>0.577364</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1295, training_loss=0.6707135671814436, metrics={'train_runtime': 12180.9963, 'train_samples_per_second': 31.813, 'train_steps_per_second': 0.106, 'total_flos': 1.019581650625536e+17, 'train_loss': 0.6707135671814436, 'epoch': 5.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Prepare test dataset for predictions\ntest_samples = []\nfor _, row in test_df.iterrows():\n    test_samples.append({\n        'id': row['id'],\n        'prompt': row['prompt'],\n        'response': row['response_a'],\n    })\n    test_samples.append({\n        'id': row['id'],\n        'prompt': row['prompt'],\n        'response': row['response_b'],\n    })\n\n# Convert to a Hugging Face Dataset\ntest_dataset = Dataset.from_dict({\n    'id': [sample['id'] for sample in test_samples],\n    'prompt': [sample['prompt'] for sample in test_samples],\n    'response': [sample['response'] for sample in test_samples],\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.528965Z","iopub.execute_input":"2025-03-11T08:59:31.529195Z","iopub.status.idle":"2025-03-11T08:59:31.540235Z","shell.execute_reply.started":"2025-03-11T08:59:31.529176Z","shell.execute_reply":"2025-03-11T08:59:31.539529Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Tokenize the test dataset\ntokenized_test = test_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.541131Z","iopub.execute_input":"2025-03-11T08:59:31.541422Z","iopub.status.idle":"2025-03-11T08:59:31.606788Z","shell.execute_reply.started":"2025-03-11T08:59:31.541388Z","shell.execute_reply":"2025-03-11T08:59:31.605838Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3afa530fc61455db7137ee3a80c30fa"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Step 3: Make predictions\npredictions = trainer.predict(tokenized_test)\npredicted_labels = np.argmax(predictions.predictions, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.608841Z","iopub.execute_input":"2025-03-11T08:59:31.609143Z","iopub.status.idle":"2025-03-11T08:59:31.822402Z","shell.execute_reply.started":"2025-03-11T08:59:31.609119Z","shell.execute_reply":"2025-03-11T08:59:31.821708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Prepare submission DataFrame\nsubmission_data = []\nfor i in range(len(tokenized_test)):\n    # The ID from the test dataset\n    sample_id = tokenized_test['id'][i]  \n    # Determining the winner based on the predicted label\n    winner = 'model_a' if predicted_labels[i] == 0 else 'model_b'\n    \n    # Append to submission data\n    submission_data.append({\n        'id': sample_id,\n        'winner': winner,\n    })\n\n# Create DataFrame\nsubmission_df = pd.DataFrame(submission_data)\n\n# Group by 'id' and take the first predicted winner for each unique id\nsubmission_df = submission_df.groupby('id', as_index=False).first()\n\n# Save as CSV\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.823276Z","iopub.execute_input":"2025-03-11T08:59:31.823601Z","iopub.status.idle":"2025-03-11T08:59:31.845499Z","shell.execute_reply.started":"2025-03-11T08:59:31.823575Z","shell.execute_reply":"2025-03-11T08:59:31.844929Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.846214Z","iopub.execute_input":"2025-03-11T08:59:31.846432Z","iopub.status.idle":"2025-03-11T08:59:31.852854Z","shell.execute_reply.started":"2025-03-11T08:59:31.846412Z","shell.execute_reply":"2025-03-11T08:59:31.852073Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        id   winner\n0   327228  model_b\n1  1139415  model_b\n2  1235630  model_a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>model_b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>model_b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>model_a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}