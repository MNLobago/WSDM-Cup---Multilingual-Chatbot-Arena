{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86946,"databundleVersionId":10131489,"sourceType":"competition"},{"sourceId":10272092,"sourceType":"datasetVersion","datasetId":6355668},{"sourceId":10272104,"sourceType":"datasetVersion","datasetId":6355678},{"sourceId":10297808,"sourceType":"datasetVersion","datasetId":6373855},{"sourceId":10298407,"sourceType":"datasetVersion","datasetId":6374257}],"dockerImageVersionId":30823,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:58.923919Z","iopub.execute_input":"2025-03-11T05:32:58.924228Z","iopub.status.idle":"2025-03-11T05:32:59.288671Z","shell.execute_reply.started":"2025-03-11T05:32:58.924194Z","shell.execute_reply":"2025-03-11T05:32:59.287803Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\n/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\n/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\n/kaggle/input/bert-model/bert_base_uncased_model/config.json\n/kaggle/input/bert-model/bert_base_uncased_model/model.safetensors\n/kaggle/input/bert-token/bert_base_token/tokenizer.json\n/kaggle/input/bert-token/bert_base_token/tokenizer_config.json\n/kaggle/input/bert-token/bert_base_token/special_tokens_map.json\n/kaggle/input/bert-token/bert_base_token/vocab.txt\n/kaggle/input/token-ml/tokenzer_ml_bert/tokenizer.json\n/kaggle/input/token-ml/tokenzer_ml_bert/tokenizer_config.json\n/kaggle/input/token-ml/tokenzer_ml_bert/special_tokens_map.json\n/kaggle/input/token-ml/tokenzer_ml_bert/vocab.txt\n/kaggle/input/model-ml/Model_ml_bert/config.json\n/kaggle/input/model-ml/Model_ml_bert/model.safetensors\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"ss = pd.read_csv(\"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\")\nss.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:59.289732Z","iopub.execute_input":"2025-03-11T05:32:59.290230Z","iopub.status.idle":"2025-03-11T05:32:59.315793Z","shell.execute_reply.started":"2025-03-11T05:32:59.290197Z","shell.execute_reply":"2025-03-11T05:32:59.314999Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        id   winner\n0   327228  model_a\n1  1139415  model_a\n2  1235630  model_a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>model_a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>model_a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>model_a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from datasets import Dataset\n\n# Load the datasets from parquet files\ntrain_df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\ntest_df = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n\n# Prepare training dataset for classification\ntrain_samples = []\nfor _, row in train_df.iterrows():\n    train_samples.append({\n        'prompt': row['prompt'],\n        'response': row['response_a'],\n        'winner': 0 if row['winner'] == 'model_a' else 1\n    })\n    train_samples.append({\n        'prompt': row['prompt'],\n        'response': row['response_b'],\n        'winner': 1 if row['winner'] == 'model_b' else 0\n    })\n\n# Convert to a Hugging Face Dataset\ntrain_dataset = Dataset.from_dict({\n    'prompt': [sample['prompt'] for sample in train_samples],\n    'response': [sample['response'] for sample in train_samples],\n    'winner': [sample['winner'] for sample in train_samples],\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:32:59.317042Z","iopub.execute_input":"2025-03-11T05:32:59.317302Z","iopub.status.idle":"2025-03-11T05:33:11.279094Z","shell.execute_reply.started":"2025-03-11T05:32:59.317261Z","shell.execute_reply":"2025-03-11T05:33:11.278191Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.279927Z","iopub.execute_input":"2025-03-11T05:33:11.280309Z","iopub.status.idle":"2025-03-11T05:33:11.290683Z","shell.execute_reply.started":"2025-03-11T05:33:11.280278Z","shell.execute_reply":"2025-03-11T05:33:11.289818Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                  id  \\\n0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n2  0003800d510e38803efba5ceaec122bc66408fe367b0be...   \n3  00072026c68f5418ef2da238394e418ce72a534b9b22d5...   \n4  0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...   \n\n                                              prompt  \\\n0                                 vieš po Slovensky?   \n1  You will be given a piece of news. Analyze it ...   \n2  Dört basamaklı, rakamları birbirinden ve sıfır...   \n3  현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...   \n4                                  Please be boring    \n\n                                          response_a  \\\n0   Áno, hovorím po slovensky. Ako vám môžem pomôcť?   \n1  Let's break down the news and analyze it accor...   \n2  Bu soruyu çözmek için, verilen koşulları adım ...   \n3  죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...   \n4  Alright, I'll be as boring as possible.\\n\\nTod...   \n\n                                          response_b   winner  \\\n0  Áno, veď som tu! Môžem ti pomôcť s otázkami al...  model_a   \n1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n2  Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...  model_a   \n3  현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...  model_b   \n4  Understood. Here is a straightforward, unadorn...  model_a   \n\n               model_a                          model_b language  \n0           o1-preview               reka-core-20240904   Slovak  \n1       gemma-2-27b-it             gemini-1.5-flash-002  Russian  \n2   gpt-4-0125-preview       claude-3-5-sonnet-20240620  Turkish  \n3        gemma-2-2b-it  llama-3.1-nemotron-70b-instruct  English  \n4  reka-flash-20240722                grok-2-2024-08-13  English  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>winner</th>\n      <th>model_a</th>\n      <th>model_b</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n      <td>vieš po Slovensky?</td>\n      <td>Áno, hovorím po slovensky. Ako vám môžem pomôcť?</td>\n      <td>Áno, veď som tu! Môžem ti pomôcť s otázkami al...</td>\n      <td>model_a</td>\n      <td>o1-preview</td>\n      <td>reka-core-20240904</td>\n      <td>Slovak</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n      <td>You will be given a piece of news. Analyze it ...</td>\n      <td>Let's break down the news and analyze it accor...</td>\n      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n      <td>model_a</td>\n      <td>gemma-2-27b-it</td>\n      <td>gemini-1.5-flash-002</td>\n      <td>Russian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003800d510e38803efba5ceaec122bc66408fe367b0be...</td>\n      <td>Dört basamaklı, rakamları birbirinden ve sıfır...</td>\n      <td>Bu soruyu çözmek için, verilen koşulları adım ...</td>\n      <td>Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...</td>\n      <td>model_a</td>\n      <td>gpt-4-0125-preview</td>\n      <td>claude-3-5-sonnet-20240620</td>\n      <td>Turkish</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00072026c68f5418ef2da238394e418ce72a534b9b22d5...</td>\n      <td>현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...</td>\n      <td>죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...</td>\n      <td>현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...</td>\n      <td>model_b</td>\n      <td>gemma-2-2b-it</td>\n      <td>llama-3.1-nemotron-70b-instruct</td>\n      <td>English</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...</td>\n      <td>Please be boring</td>\n      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n      <td>Understood. Here is a straightforward, unadorn...</td>\n      <td>model_a</td>\n      <td>reka-flash-20240722</td>\n      <td>grok-2-2024-08-13</td>\n      <td>English</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df[\"language\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.293361Z","iopub.execute_input":"2025-03-11T05:33:11.293587Z","iopub.status.idle":"2025-03-11T05:33:11.314682Z","shell.execute_reply.started":"2025-03-11T05:33:11.293567Z","shell.execute_reply":"2025-03-11T05:33:11.314037Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['Slovak', 'Russian', 'Turkish', 'English', 'Korean', 'Swedish',\n       'Vietnamese', 'Finnish', 'unknown', 'Chinese', 'Hungarian',\n       'Spanish', 'Polish', 'Japanese', 'Dutch', 'German', 'Yiddish',\n       'Italian', 'French', 'Indonesian', 'Persian', 'Portuguese',\n       'Catalan', 'Czech', 'Ukrainian', 'Arabic', 'Bislama', 'Bulgarian',\n       'Romanian', 'Armenian', 'Xhosa', 'Yoruba', 'Thai', 'Serbian',\n       'Slovenian', 'Tamil', 'Sanskrit', 'xx', 'Malay', 'Swahili',\n       'Irish', 'Lithuanian', 'Waray', 'Kyrgyz', 'Kalaallisut', 'Latin',\n       'Nauru', 'Corsican', 'Khasi', 'Norwegian', 'Hebrew', 'Faroese',\n       'Azerbaijani', 'Danish', 'Abkhazian', 'Oromo', 'Ganda', 'Zhuang',\n       'Estonian', 'Basque', 'Uzbek', 'Pashto', 'Afrikaans', 'Scots',\n       'Macedonian', 'Greek', 'Luxembourgish', 'Latvian', 'Wolof',\n       'Croatian', 'Esperanto', 'Galician', 'Javanese', 'Bosnian',\n       'Tongan', 'Belarusian', 'Bangla', 'Romansh', 'Sundanese',\n       'Tagalog', 'Southern Sotho', 'Mongolian', 'Dzongkha',\n       'Norwegian Nynorsk', 'Khmer', 'Amharic', 'Shona', 'Bashkir',\n       'Inuktitut', 'Afar', 'Malagasy', 'Icelandic', 'Manx',\n       'Interlingue', 'Occitan', 'Interlingua', 'Tsonga', 'Swati',\n       'Tatar', 'Tibetan', 'Hindi', 'Assamese', 'Haitian Creole',\n       'Albanian', 'Hmong', 'Kinyarwanda', 'Welsh', 'Turkmen', 'Akan',\n       'Rundi', 'zzp', 'Aymara', 'Hausa', 'Guarani', 'Nyanja',\n       'Scottish Gaelic', 'Tswana', 'Lingala', 'Kazakh', 'Breton',\n       'Klingon', 'Volapük', 'Hawaiian', 'Kurdish', 'Quechua', 'Samoan',\n       'Telugu', 'Sindhi'], dtype=object)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.315933Z","iopub.execute_input":"2025-03-11T05:33:11.316178Z","iopub.status.idle":"2025-03-11T05:33:11.331648Z","shell.execute_reply.started":"2025-03-11T05:33:11.316158Z","shell.execute_reply":"2025-03-11T05:33:11.330851Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id                                             prompt  \\\n0   327228  Caso Clínico: Un hombre de 70 años con anteced...   \n1  1139415   Peel Company received a cash dividend from a ...   \n2  1235630  Há um grave problema com o relógio da torre da...   \n\n                                          response_a  \\\n0  **Diagnóstico Diferencial de Anemia en Pacient...   \n1  The correct answer is **(a) No   No**. Here's ...   \n2  Dois problemas interessantes!\\n\\n**Problema 1:...   \n\n                                          response_b  scored  \n0  Basándonos en el caso clínico presentado, pode...   False  \n1  The correct answer is **(a) No No**. Here's wh...   False  \n2  Vamos resolver os dois problemas em sequência....   False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>response_a</th>\n      <th>response_b</th>\n      <th>scored</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>Caso Clínico: Un hombre de 70 años con anteced...</td>\n      <td>**Diagnóstico Diferencial de Anemia en Pacient...</td>\n      <td>Basándonos en el caso clínico presentado, pode...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>Peel Company received a cash dividend from a ...</td>\n      <td>The correct answer is **(a) No   No**. Here's ...</td>\n      <td>The correct answer is **(a) No No**. Here's wh...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>Há um grave problema com o relógio da torre da...</td>\n      <td>Dois problemas interessantes!\\n\\n**Problema 1:...</td>\n      <td>Vamos resolver os dois problemas em sequência....</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Use a subset of the dataset for quick testing\n#train_dataset = train_dataset.select(range(2000))  # Select first 1000 examples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.332244Z","iopub.execute_input":"2025-03-11T05:33:11.332436Z","iopub.status.idle":"2025-03-11T05:33:11.341899Z","shell.execute_reply.started":"2025-03-11T05:33:11.332410Z","shell.execute_reply":"2025-03-11T05:33:11.341269Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.342580Z","iopub.execute_input":"2025-03-11T05:33:11.342774Z","iopub.status.idle":"2025-03-11T05:33:11.353856Z","shell.execute_reply.started":"2025-03-11T05:33:11.342751Z","shell.execute_reply":"2025-03-11T05:33:11.352859Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'response', 'winner'],\n    num_rows: 96878\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\nimport torch.nn.utils.weight_norm\nimport torch.nn as nn\n\nclass WeightNormModel(AutoModelForSequenceClassification):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Applying weight normalization on the classifier layer\n        self.classifier = torch.nn.utils.weight_norm(self.classifier)\n\n# Load your model with weight normalization\n#model = WeightNormModel.from_pretrained(\n    #\"/kaggle/input/bert-model/bert_base_uncased_model\",\n    #num_labels=2,\n#)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"/kaggle/input/model-ml/Model_ml_bert\",  # You can choose other model variants as well\n    num_labels=2,\n    id2label={0: \"model_a\", 1: \"model_b\"},  # Labels corresponding to models\n    label2id={\"model_a\": 0, \"model_b\": 1},\n)\n\n# Freeze all parameters in the base model\nfor param in model.base_model.parameters():\n    param.requires_grad = False\n\n# Unfreeze the last 3 layers of the transformer\nnum_layers = len(model.base_model.encoder.layer)\nfor layer in model.base_model.encoder.layer[num_layers-3:]:\n    for param in layer.parameters():\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:11.354713Z","iopub.execute_input":"2025-03-11T05:33:11.354995Z","iopub.status.idle":"2025-03-11T05:33:16.728657Z","shell.execute_reply.started":"2025-03-11T05:33:11.354975Z","shell.execute_reply":"2025-03-11T05:33:16.727963Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of parameters that require gradients: {total_parameters}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:16.729455Z","iopub.execute_input":"2025-03-11T05:33:16.729894Z","iopub.status.idle":"2025-03-11T05:33:16.735233Z","shell.execute_reply.started":"2025-03-11T05:33:16.729846Z","shell.execute_reply":"2025-03-11T05:33:16.734372Z"}},"outputs":[{"name":"stdout","text":"Number of parameters that require gradients: 21265154\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\nfrom transformers import AutoTokenizer\nfrom datasets import DatasetDict\nimport torch\nimport random\n\n# Set random seed for reproducibility\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n\n# Ensure deterministic behavior\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/token-ml/tokenzer_ml_bert\")\n\n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(examples['prompt'], examples['response'], return_tensors='pt', padding=True, truncation=True)\n\n# Tokenize the dataset\ntokenized_train = train_dataset.map(\n    lambda examples: {\n        **tokenize_function(examples),\n        \"labels\": examples[\"winner\"],  # Replace 'label' with the actual column name in your dataset\n    },\n    batched=True,\n)\n\n# Split the tokenized_train dataset into training and evaluation datasets\nsplit_datasets = tokenized_train.train_test_split(test_size=0.2, seed=42)  # Adjust test_size as needed\ntokenized_train = split_datasets[\"train\"]\ntokenized_eval = split_datasets[\"test\"]\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {\"accuracy\": (predictions == labels).mean()}\n\n\n# Prepare training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./model_output\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=150,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\",  # Disable logging to WandB\n)\n\n# Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_eval,  # Provide a validation dataset\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,  # Add compute_metrics\n)\n\n# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T05:33:16.736093Z","iopub.execute_input":"2025-03-11T05:33:16.736327Z","iopub.status.idle":"2025-03-11T08:59:31.528209Z","shell.execute_reply.started":"2025-03-11T05:33:16.736297Z","shell.execute_reply":"2025-03-11T08:59:31.527517Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/96878 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ba6b8401f874b52ae2562f8adf855cb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1295' max='1295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1295/1295 3:22:52, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.693700</td>\n      <td>0.693084</td>\n      <td>0.507690</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.691500</td>\n      <td>0.692130</td>\n      <td>0.513625</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.688400</td>\n      <td>0.688886</td>\n      <td>0.535456</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.657400</td>\n      <td>0.685461</td>\n      <td>0.567971</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.600900</td>\n      <td>0.705334</td>\n      <td>0.577364</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1295, training_loss=0.6707135671814436, metrics={'train_runtime': 12180.9963, 'train_samples_per_second': 31.813, 'train_steps_per_second': 0.106, 'total_flos': 1.019581650625536e+17, 'train_loss': 0.6707135671814436, 'epoch': 5.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Prepare test dataset for predictions\ntest_samples = []\nfor _, row in test_df.iterrows():\n    test_samples.append({\n        'id': row['id'],\n        'prompt': row['prompt'],\n        'response': row['response_a'],\n    })\n    test_samples.append({\n        'id': row['id'],\n        'prompt': row['prompt'],\n        'response': row['response_b'],\n    })\n\n# Convert to a Hugging Face Dataset\ntest_dataset = Dataset.from_dict({\n    'id': [sample['id'] for sample in test_samples],\n    'prompt': [sample['prompt'] for sample in test_samples],\n    'response': [sample['response'] for sample in test_samples],\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.528965Z","iopub.execute_input":"2025-03-11T08:59:31.529195Z","iopub.status.idle":"2025-03-11T08:59:31.540235Z","shell.execute_reply.started":"2025-03-11T08:59:31.529176Z","shell.execute_reply":"2025-03-11T08:59:31.539529Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Tokenize the test dataset\ntokenized_test = test_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.541131Z","iopub.execute_input":"2025-03-11T08:59:31.541422Z","iopub.status.idle":"2025-03-11T08:59:31.606788Z","shell.execute_reply.started":"2025-03-11T08:59:31.541388Z","shell.execute_reply":"2025-03-11T08:59:31.605838Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3afa530fc61455db7137ee3a80c30fa"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Step 3: Make predictions\npredictions = trainer.predict(tokenized_test)\npredicted_labels = np.argmax(predictions.predictions, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.608841Z","iopub.execute_input":"2025-03-11T08:59:31.609143Z","iopub.status.idle":"2025-03-11T08:59:31.822402Z","shell.execute_reply.started":"2025-03-11T08:59:31.609119Z","shell.execute_reply":"2025-03-11T08:59:31.821708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Prepare submission DataFrame\nsubmission_data = []\nfor i in range(len(tokenized_test)):\n    # The ID from the test dataset\n    sample_id = tokenized_test['id'][i]  \n    # Determining the winner based on the predicted label\n    winner = 'model_a' if predicted_labels[i] == 0 else 'model_b'\n    \n    # Append to submission data\n    submission_data.append({\n        'id': sample_id,\n        'winner': winner,\n    })\n\n# Create DataFrame\nsubmission_df = pd.DataFrame(submission_data)\n\n# Group by 'id' and take the first predicted winner for each unique id\nsubmission_df = submission_df.groupby('id', as_index=False).first()\n\n# Save as CSV\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.823276Z","iopub.execute_input":"2025-03-11T08:59:31.823601Z","iopub.status.idle":"2025-03-11T08:59:31.845499Z","shell.execute_reply.started":"2025-03-11T08:59:31.823575Z","shell.execute_reply":"2025-03-11T08:59:31.844929Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:59:31.846214Z","iopub.execute_input":"2025-03-11T08:59:31.846432Z","iopub.status.idle":"2025-03-11T08:59:31.852854Z","shell.execute_reply.started":"2025-03-11T08:59:31.846412Z","shell.execute_reply":"2025-03-11T08:59:31.852073Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"        id   winner\n0   327228  model_b\n1  1139415  model_b\n2  1235630  model_a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>327228</td>\n      <td>model_b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1139415</td>\n      <td>model_b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1235630</td>\n      <td>model_a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}